---
title: "Wasted on data: Exploring the wine dataset"
author: 'Jose Francisco Endrinal'
output: github_document
---

Whether you're a drinker or not, chances are that alcohol has played some part in the culture of where you live. It would be awesome to take measurements on any wine and be able to determine what kind of wine it was. In this dataset, we're sticking with three unidentified types of wine.  

The wine dataset is a series of measurements of different samples of three types of wine. In this dataset, there are thirteen characteristics that were measured:
 	1. Alcohol
 	2. Malic acid
 	3. Ash
	4. Alcalinity of ash  
 	5. Magnesium
	6. Total phenols
 	7. Flavanoids
 	8. Nonflavanoid phenols
 	9. Proanthocyanins
	10. Color intensity
 	11. Hue
 	12. OD280/OD315 of diluted wines
 	13. Proline  

Unfortunately, we do not have the units of these measurements and simply have to rely on their relative values.  

```{r warning=FALSE, message=FALSE}
# Loading package
suppressPackageStartupMessages({
  library(nnet)
  library(tidyverse)
  library(modelr)})
#Loading dataset
read_csv("data/wine.csv") %>% 
  rename(class = X1, 
         alcohol = X2, 
         mall.Ac = X3, 
         ash = X4, 
         alk.Ash = X5, 
         magnes = X6, 
         tot.Phen = X7, 
         flavan = X8, 
         nonFl.ph = X9, 
         proanth = X10, 
         col.Int = X11, 
         hue = X12, 
         dil = X13, 
         proline = X14) -> wine
```

```{r echo=FALSE}
wine
```
Looking at the dataset alone, we can see that most of these variables are continuous. But we have too many characteristics to work with, hurting the insight we could gain. Let's try to do what we did last time with our [breast cancer dataset](). We need to see if there may be an apparent way to separate the classes and the characteristics based on visualization alone. 

### Exploratory data analysis

Let's see which variables we can use to divide the data classes. Unlike our previous post on the breast cancer dataset, this data is continuous data. Which means that we need to look at the smoothened distribution rather than the discrete occurences.  

Our visualization looks like the following: 
```{r warning=FALSE}
mutate(wine, class = as.character(class)) %>% 
  mutate_if(is.numeric, scale) %>% # change to z-scores
  gather(key, value, -class) %>% 
  ggplot(aes(x = value)) + 
  geom_density(aes(fill = class), position = "stack") + 
  facet_wrap(~ key, ncol = 4)
```

dil, hue and tot.Phen here look like they can divide the red and blue class well. col.Int has the green and blue class on either side. proline differentiates the red and green class well. I'll try and think of a deliberate way to pick variables in a future post, by this is the best I have so far. In the future, I'll be using feature selection methods that don't require expert judgement (filter, wrapper methods, etc.) and instead rely on statistical methods to weed out variables. 

Using these variables, we'd like to know if a multinomial logistic regression model would work in separating these three classes well and how well we can improve it.  

## Training and Testing Sets

Like in our previous post, let us make 100 training and testing sets for our dataset.  
```{r}
set.seed(2387)
tt.sets <- select(wine, 
                  class, 
                  dil, 
                  hue, 
                  tot.Phen, 
                  col.Int, 
                  proline) %>% 
  mutate(class = as.character(class) %>% as_factor) %>% 
  crossv_mc(n = 100, test = 0.3) %>% 
  mutate(ind.tr = map(train, as.integer), 
         ind.te = map(test, as.integer), 
         train.s = map(train, as_data_frame), 
         test.s = map(test, as_data_frame))
```

```{r}
tt.sets
```

Now that we have the train and test sets, we can build our multinomial logistic regression model using the `nnet` package.  

## Building the multinomial regression model
We will structure the function we will use to map the training sets so that the output of this function is a model. What makes this model different from the normal logistic regression model is that this model is for a class where the values are not 1 or 0. In this case, the values can be 1, 2, or 3.  

```{r}
mnom <- function(df){
  multinom(class ~ 
             dil + 
             hue + 
             tot.Phen + 
             col.Int + 
             proline, 
           data = df, 
           trace = FALSE)}
```
We have enabled `trace` to be `FALSE` so that no messages will display.   

Now for the predicting and response functions:  
```{r}
mnom_predict <- function(model, df){
  preds <- predict(model, newdata = select(df, -class), type = "class")}
mnom_response <- function(df){
  df[["class"]]}
```

## Training and testing the model

As in the same way we did it in my previous post, our recipe for training and testing our model will be done in the following way.  
```{r}
# average score
mnom_mscore <- function(pred, resp){
  df <- pred == resp
  mean(df)}
# create new variables
tt.sets <- tt.sets %>% 
  mutate(model = map(train.s, mnom), 
         pred = map2(model, test.s, mnom_predict), 
         resp = map(test.s, mnom_response), 
         hit = map2_dbl(pred, resp, mnom_mscore))
score <- summarise(tt.sets, score = mean(hit))
score[[1]]
```

With an accuraccy of about ~93 percent, this model can still do better, but this is a great starting point for it.  

```{r echo=FALSE}
rm(mnom, mnom_mscore, mnom_predict, mnom_response)
rm(score)
```


## Distribution of scores

Let's see how densely the scores are together so that we can see how likely it is to have another score other than our ~93 percent average.  

```{r}
select(tt.sets, hit) %>% 
  ggplot(aes(x = hit)) + 
  geom_density(fill = "#87CEFA")
```

The distribution is not gaussian, but more scores ten toward a ~95 percent accuracy on the part of this model.  

```{r echo=FALSE}
rm(tt.sets)
```


## Visualizing the effect of a multinomial regression

We visualize the effect of two variables on the regression and see if a clear joint relationship can be seen with regard to separation.  

```{r}
# Generate variable pair combinations of 2
select(wine, 
       dil, 
       hue, 
       tot.Phen, 
       col.Int, 
       proline) %>% 
  tbl_vars %>% 
  combn(2) %>% 
  as_tibble %>% 
  gather %>% 
  rename(pair = key) %>% 
  mutate(elem = rep(c("X1", "X2"), 10)) %>% 
  spread(key = elem, value = value) %>% 
  select(-pair) -> value.prs
# Function to extract value from wine dataset
subset_frm_wine <- function(id, var) {
  rescol <- wine[, var] %>% scale
  res <- rescol[id]
  as.numeric(unlist(res))}
# Gather and spread to two 
select(wine, 
       class) %>% 
  mutate(
    class = as.character(class), 
    id = 1:n()) %>% 
  mutate(pairs = list(value.prs)) %>% 
  unnest() %>% 
  mutate(Y1 = map2_dbl(id, X1, subset_frm_wine), 
         Y2 = map2_dbl(id, X2, subset_frm_wine)) %>% 
  ggplot(aes(x = Y1, y = Y2)) + 
  geom_point(aes(color = class)) + 
  facet_grid(X1 ~ X2)
```
Whenever `proline` is used with variables like `col.Int`, `dil`, `hue`,  and `tot.Phen`, the classes (the dots) seem to separate nicely. I'm considering having interaction models for these variables in a future post, but now we know that these variables work really well to separate the classes, at least in the way we visualized them in 2D space.   

Let's try doing that same visualization, but this time, we try to show where the points were classified correctly and incorrectly in this dataset.  

```{r echo=FALSE}
rm(subset_frm_wine)
rm(value.prs, wine)
```

