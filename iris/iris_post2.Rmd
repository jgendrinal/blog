---
title: "Back to Iris: testing in R"
author: 'Jose Francisco Endrinal'
output: github_document
---

*DISCLAIMER: I am not a working data analyst, nor am I a data scientist. As such, the code, techniques, and methods used in this blog post do not qualify as industry-level code, techniques, and methods. This blog and its corresponding github repository are meant to document my progress as I come to learn the techniques and skills a data analyst or data scientist will be needing in their line of work. This style of learning is popularly called "Learning in Public"*  

## Introduction

Great data analysis seems to have all the steps carefully checked out and evaluated. And since data analysis is done in code, so it goes that the code we write should be checked out and evaluated. We can manually try to run our R code on the console over and over again, but it becomes really difficult when you have so much code and so much data, models, and functions to test.  

Fortunately for us, there are conventions in coding that help us automatically test our code for whatever conditions we want to apply. There is a practice called test-driven programming (TTP) where software engineers write out the tests that their code has to satisfy. Data analysis experts have taken this convention and called it test-driven data analysis (TTDA).   

Testing your code has now become an important part of the data analysis process. For one, every step of processing data works under certain assumptions. It's not always the case that those assumptions are true. And when your assumptions are not in check, the steps in your analysis break down.  

Another reason to test your code is that models also have the same assumption. In linear regression alone, there are five major assumptions that you have to keep in order to the results of linear regression to be unbiased. Testing your code ensures that the model fulfills all those assumptions.  

There are two testing packages in R `assertthat` and `testthat`. `assertthat` gives modules to test particular functions. These tests help ensure that the code receives the right inputs for the function to work. `testthat` is a package for what are called unit tests, which tests the outputs of certain function for any condition you give it.  

We'll be trying to use `testthat` and `assertthat` in this post to test a prelimenary model for the iris dataset on the first blog post.  

## Setup

```{r setup warning=FALSE, message=FALSE}
# Load packages
suppressPackageStartupMessages({
  library(tidyverse)
  library(testthat) # for unit tests
  library(assertthat)}) # for function tests
# Load dataset
read_csv("data/iris.csv") %>% 
  # Rename to better variable names
  rename(p_length = X1, 
         s_length = X2, 
         p_width = X3, 
         s_width = X4, 
         class = X5) %>% 
  # Remove `Iris-` from class
  mutate(
    class = recode(class, 
                   "Iris-setosa" = "setosa", 
                   "Iris-versicolor"= "versicolor", 
                   "Iris-virginica" = "virginica")) -> iris.dt
```

## First look at the dataset

```{r firstlook}
# View dataset
iris.dt
```


## Exploratory Data Analysis

```{r eda}
# Distribution of the class/target over the variable
gather(iris.dt, key = "measure", value = "value", -class) %>% 
  ggplot(aes(value)) + 
  geom_density(aes(fill = class, 
                   color = class), 
               alpha = 0.5, 
               position = "identity") + 
  facet_wrap(~ measure)
```

## Testing our data

```{r testdata, error=TRUE}
test_that("Petal lengths are normally distributed", {
  filter(iris.dt, class == "setosa")[["p_length"]] %>% 
    shapiro.test(.) -> setosa
  filter(iris.dt, class == "versicolor")[["p_length"]] %>% 
    shapiro.test(.) -> versicolor
  filter(iris.dt, class == "virginica")[["p_length"]] %>% 
    shapiro.test(.) -> virginica
  expect_lt(setosa$p.value, 0.05)
  expect_lt(versicolor$p.value, 0.05)
  expect_lt(virginica$p.value, 0.05)
})
test_that("Petal widths are normally distributed", {
  filter(iris.dt, class == "setosa")[["p_width"]] %>% 
    shapiro.test(.) -> setosa
  filter(iris.dt, class == "versicolor")[["p_width"]] %>% 
    shapiro.test(.) -> versicolor
  filter(iris.dt, class == "virginica")[["p_width"]] %>% 
    shapiro.test(.) -> virginica
  expect_lt(setosa$p.value, 0.05)
  expect_lt(versicolor$p.value, 0.05)
  expect_lt(virginica$p.value, 0.05)
})
test_that("Sepal lengths are normally distributed", {
  filter(iris.dt, class == "setosa")[["s_length"]] %>% 
    shapiro.test(.) -> setosa
  filter(iris.dt, class == "versicolor")[["s_length"]] %>% 
    shapiro.test(.) -> versicolor
  filter(iris.dt, class == "virginica")[["s_length"]] %>% 
    shapiro.test(.) -> virginica
  expect_lt(setosa$p.value, 0.05)
  expect_lt(versicolor$p.value, 0.05)
  expect_lt(virginica$p.value, 0.05)
})
test_that("Sepal widths are normally distributed", {
  filter(iris.dt, class == "setosa")[["s_width"]] %>% 
    shapiro.test(.) -> setosa
  filter(iris.dt, class == "versicolor")[["s_width"]] %>% 
    shapiro.test(.) -> versicolor
  filter(iris.dt, class == "virginica")[["s_width"]] %>% 
    shapiro.test(.) -> virginica
  expect_lt(setosa$p.value, 0.05)
  expect_lt(versicolor$p.value, 0.05)
  expect_lt(virginica$p.value, 0.05)
})
```



***
More dataset information: [[Dataset description]](link to website)  

Feedback:  
Email: francis.endrinal@gmail.com  
FB Messenger: m.me/transparencyman  
Twitter, Instagram: @jgendrinal
